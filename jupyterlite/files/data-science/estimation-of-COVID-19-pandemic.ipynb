{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of COVID-19 pandemic\n",
    "\n",
    "## Loading data\n",
    "\n",
    "We will use data on COVID-19 infected individuals, provided by the [Center for Systems Science and Engineering](https://systems.jhu.edu/) (CSSE) at [Johns Hopkins University](https://jhu.edu/). Dataset is available in [this GitHub Repository](https://github.com/CSSEGISandData/COVID-19)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import ipytest\n",
    "import unittest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ipytest.autoconfig()\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 3) # make figures larger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the most recent data directly from GitHub using `pd.read_csv`. If for some reason the data is not available, you can always use the copy available locally in the `data` folder - just uncomment the line below that defines `base_url`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/\" # loading from Internet\n",
    "# base_url = \"../../data/COVID/\" # loading from disk\n",
    "infected_dataset_url = base_url + \"time_series_covid19_confirmed_global.csv\"\n",
    "recovered_dataset_url = base_url + \"time_series_covid19_recovered_global.csv\"\n",
    "deaths_dataset_url = base_url + \"time_series_covid19_deaths_global.csv\"\n",
    "countries_dataset_url = base_url + \"../UID_ISO_FIPS_LookUp_Table.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load the data for infected individuals and see how the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infected = pd.read_csv(infected_dataset_url)\n",
    "infected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each row of the table defines the number of infected individuals for each country and/or province, and columns correspond to dates. Similar tables can be loaded for other data, such as number of recovered and number of deaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recovered = pd.read_csv(recovered_dataset_url)\n",
    "deaths = pd.read_csv(deaths_dataset_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sense of the data\n",
    "\n",
    "From the table above the role of province column is not clear. Let's see the different values that are present in `Province/State` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infected['Province/State'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the names we can deduce that countries like Australia and China have more detailed breakdown by provinces. Let's look for information on China to see the example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(df, column_name, column_value):\n",
    "    return df[df[column_name]==column_value]\n",
    "\n",
    "filter(infected, 'Country/Region', 'China')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the data \n",
    "\n",
    "We are not interested in breaking countries down to further territories, thus we would first get rid of this breakdown and add information on all territories together, to get info for the whole country. This can be done using `groupby`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Onecolumn_groupby_sum(df, column_name):\n",
    "    if df is None:\n",
    "        raise Exception('df cannot be None.')\n",
    "    if column_name not in df:\n",
    "        raise Exception('Column does not exist.')\n",
    "    return df.groupby(column_name).sum()\n",
    "\n",
    "infected = get_Onecolumn_groupby_sum(infected, 'Country/Region')\n",
    "recovered = get_Onecolumn_groupby_sum(recovered, 'Country/Region')\n",
    "deaths = get_Onecolumn_groupby_sum(deaths, 'Country/Region')\n",
    "\n",
    "infected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5><font color=blue>Check result by executing below... üìù</font></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -qq\n",
    "\n",
    "def create_test_df():\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            'c1': [1, 2, 3, 4, 5], \n",
    "            'c2': [6, 7, 8, 9, 10]\n",
    "        }\n",
    "    )\n",
    "\n",
    "class Test_Onecolumn_groupby_sum(unittest.TestCase):\n",
    "\n",
    "    def test_get_Onecolumn_groupby_sum_happy_case(self):\n",
    "        # assign\n",
    "        test_df = create_test_df()\n",
    "\n",
    "        # act\n",
    "        actual_result = get_Onecolumn_groupby_sum(test_df, 'c1')\n",
    "    \n",
    "\n",
    "        # assert\n",
    "        assert actual_result.iloc[0, 0] == 6\n",
    "\n",
    "    def test_get_Onecolumn_groupby_sum_with_none_df(self):\n",
    "        #act\n",
    "        with pytest.raises(Exception):\n",
    "            get_Onecolumn_groupby_sum(None, 'c1')\n",
    "        \n",
    "    def test_get_Onecolumn_groupby_sum_with_invalid_column_name(self):\n",
    "        #assign\n",
    "        test_df = create_test_df()\n",
    "    \n",
    "        #act\n",
    "        with pytest.raises(Exception):\n",
    "            get_Onecolumn_groupby_sum(test_df, 'c100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<details><summary>üë©‚Äçüíª <b>Hint</b></summary>\n",
    "\n",
    "You can consider to use <code>pandas.DataFrame.groupby()</code> and <code>sum()</code>.\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that due to using `groupby` all DataFrames are now indexed by Country/Region. We can thus access the data for a specific country by using `.loc`:|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_infected_vs_recovered():\n",
    "    infected.loc['US'][2:].plot()\n",
    "    recovered.loc['US'][2:].plot()\n",
    "    plt.show()\n",
    "\n",
    "plot_infected_vs_recovered()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note** how we use `[2:]` to remove first two elements of a sequence that contain geolocation of a country. We can also drop those two columns altogether:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df, columns):\n",
    "    if df is None:\n",
    "        raise Exception('df cannot be None.')\n",
    "#  I want to test some invalid columns, but I can't write the code due to my poor programming skills, so I left some comments.\n",
    "#     if columns not in df:\n",
    "#         raise Exception('Columns does not exist.')\n",
    "    return df.drop(columns=columns,inplace=True)\n",
    "\n",
    "drop_columns(infected,['Lat', 'Long'])\n",
    "drop_columns(recovered,['Lat', 'Long'])\n",
    "drop_columns(deaths,['Lat', 'Long'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5><font color=blue>Check result by executing below... üìù</font></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -qq\n",
    "\n",
    "def create_test_df():\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            'c1': [1, 2, 3, 4, 5], \n",
    "            'c2': [6, 7, 8, 9, 10],\n",
    "            'c3': [11, 12, 13, 14, 15],\n",
    "            'c4': [16, 17, 18, 19, 20]\n",
    "        }\n",
    "    )\n",
    "\n",
    "class Test_drop_columns(unittest.TestCase):\n",
    "\n",
    "    def test_drop_columns_happy_case(self):\n",
    "        # assign\n",
    "        test_df = create_test_df()\n",
    "\n",
    "        # act\n",
    "        drop_columns(test_df,['c1', 'c2'])\n",
    "    \n",
    "        # assert\n",
    "        assert test_df.iloc[0, 0] == 11\n",
    "\n",
    "    def test_drop_columns_with_none_df(self):\n",
    "        #act\n",
    "        with pytest.raises(Exception):\n",
    "            get_drop_columns(None,'c1')\n",
    "        \n",
    "#  I want to test some invalid columns, but I can't write the code due to my poor programming skills, so I left some comments.\n",
    "#     if columns not in df:        \n",
    "#     def test_drop_columns_with_valid_and_invalid_column_name(self):\n",
    "#         #assign\n",
    "#         test_df = create_test_df()\n",
    "    \n",
    "#         #act\n",
    "\n",
    "#         drop_columns(test_df,['c100','c1','c2'])\n",
    "        \n",
    "#         # assert\n",
    "#         assert test_df.iloc[0, 0] == 11\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<details><summary>üë©‚Äçüíª <b>Hint</b></summary>\n",
    "\n",
    "You can consider to use <code>drop</code>.\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the data\n",
    "\n",
    "Let's now switch to investigating a specific country. Let's create a frame that contains the data on infections indexed by date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkframe(country):\n",
    "    df = pd.DataFrame({ 'infected' : infected.loc[country] ,\n",
    "                        'recovered' : recovered.loc[country],\n",
    "                        'deaths' : deaths.loc[country]})\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    return df\n",
    "\n",
    "df = mkframe('US')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<details><summary>üë©‚Äçüíª <b>Hint</b></summary>\n",
    "\n",
    "You can consider to use <code>pandas.to_datetime</code>.\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the number of new infected people each day. This will allow us to see the speed at which pandemic progresses. The easiest day to do it is to use `diff`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_column_to_show_by_getting_column_to_diff(df, column_name_to_show , column_name_to_diff):\n",
    "    df[column_name_to_show]=df[column_name_to_diff].diff()\n",
    "    df[column_name_to_show].plot()\n",
    "    plt.show()\n",
    "\n",
    "plot_column_to_show_by_getting_column_to_diff(df, 'ninfected', 'infected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<details><summary>üë©‚Äçüíª <b>Hint</b></summary>\n",
    "\n",
    "You can consider to use <code>diff()</code>.\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see high fluctuations in data. Let's look closer at one of the months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_infected_by_year_and_month(df, year, month):\n",
    "    return df[(df.index.year==year) & (df.index.month==month)]['ninfected'].plot()\n",
    "\n",
    "get_non_infected_by_year_and_month(df, 2020, 7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It clearly looks like there are weekly fluctuations in data. Because we want to be able to see the trends, it makes sense to smooth out the curve by computing running average (i.e. for each day we will compute the average value of the previous several days):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling_window(df, column, window):\n",
    "    return df[column].rolling(window)\n",
    "\n",
    "df['ninfav']=get_rolling_window(df, 'ninfected', 7).mean()\n",
    "df['ninfav'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to compare several countries, we might want to take the country's population into account, and compare the percentage of infected individuals with respect to country's population. In order to get country's population, let's load the dataset of countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv(countries_dataset_url)\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this dataset contains information on both countries and provinces, to get the population of the whole country we need to be a little bit clever: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_country_region(df, country_region):\n",
    "    return df[(df['Country_Region']==country_region)&df['Province_State'].isna()]\n",
    "\n",
    "filter_by_country_region(countries, 'US')\n",
    "\n",
    "# Before\n",
    "# countries[(countries['Country_Region']=='US') ____ countries['Province_State'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pinfected(df):\n",
    "    pop=filter_by_country_region(countries, 'US')['Population'].iloc[0]\n",
    "    return df['infected']*100/pop\n",
    "\n",
    "df['pinfected'] = get_pinfected(df)\n",
    "df['pinfected'].plot(figsize=(10, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<details><summary>üë©‚Äçüíª <b>Hint</b></summary>\n",
    "\n",
    "You can consider to use <code>&</code>\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Computing $R_t$\n",
    "\n",
    "To see how infectious is the disease, we look at the **basic reproduction number** $R_0$, which indicated the number of people that an infected person would further infect. When $R_0$ is more than 1, the epidemic is likely to spread.\n",
    "\n",
    "$R_0$ is a property of the disease itself, and does not take into account some protective measures that people may take to slow down the pandemic. During the pandemic progression, we can estimate the reproduction number $R_t$ at any given time $t$. It has been shown that this number can be roughly estimated by taking a window of 8 days, and computing $$R_t=\\frac{I_{t-7}+I_{t-6}+I_{t-5}+I_{t-4}}{I_{t-3}+I_{t-2}+I_{t-1}+I_t}$$\n",
    "where $I_t$ is the number of newly infected individuals on day $t$.\n",
    "\n",
    "Let's compute $R_t$ for our pandemic data. To do this, we will take a rolling window of 8 `ninfected` values, and apply the function to compute the ratio above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rt(df, column_name, window):\n",
    "    df['Rt']=get_rolling_window(df, column_name, window).apply(lambda x: x[4:].sum()/x[:4].sum())\n",
    "    return df['Rt']\n",
    "\n",
    "get_rt(df, 'ninfected', 8)\n",
    "df['Rt'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<details><summary>üë©‚Äçüíª <b>Hint</b></summary>\n",
    "\n",
    "You can consider to use <code>lambda</code>\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there are some gaps in the graph. Those can be caused by either `NaN`, if  `inf` values being present in the dataset. `inf` may be caused by division by 0, and `NaN` can indicate missing data, or no data available to compute the result (like in the very beginning of our frame, where rolling window of width 8 is not yet available). To make the graph nicer, we need to fill those values using `replace` and `fillna` function.\n",
    "\n",
    "Let's further look at the beginning of the pandemic. We will also limit the y-axis values to show only values below 6, in order to see better, and draw horizontal line at 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rt_ax(df):\n",
    "    return df[df.index<\"2020-05-01\"]['Rt'].replace(np.inf,np.nan).replace(method='pad')\n",
    "\n",
    "ax = get_rt_ax(df).plot(figsize=(10, 3))\n",
    "ax.set_ylim([0, 6])\n",
    "ax.axhline(1, linestyle='--', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting indicator of the pandemic is the **derivative**, or **daily difference** in new cases. It allows us to see clearly when pandemic is increasing or declining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df_column_diff(df, column_name):\n",
    "    df[column_name].diff().plot()\n",
    "    plt.show()\n",
    "\n",
    "plot_df_column_diff(df, 'ninfected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<details><summary>üë©‚Äçüíª <b>Hint</b></summary>\n",
    "\n",
    "You can consider to use <code>pandas.DataFrame.diff()</code> \n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the fact that there are a lot of fluctuations in data caused by reporting, it makes sense to smooth the curve by running rolling average to get the overall picture. Let's again focus on the first months of the pandemic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_before(df, datetime):\n",
    "    return df[df.index<datetime]\n",
    "\n",
    "def diff(df):\n",
    "    return df.diff()\n",
    "\n",
    "ax=get_rolling_window(diff(filter_data_before(df, '2020-06-01')), 'ninfected', 7).mean().plot()\n",
    "ax.axhline(0,linestyle='-.',color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Challenge\n",
    "\n",
    "Now it is time for you to play more with the code and data! Here are a few suggestions you can experiment with:\n",
    "* See the spread of the pandemic in different countries.\n",
    "* Plot $R_t$ graphs for several countries on one plot for comparison, or make several plots side-by-side\n",
    "* See how the number of deaths and recoveries correlate with number of infected cases.\n",
    "* Try to find out how long a typical disease lasts by visually correlating infection rate and deaths rate and looking for some anomalies. You may need to look at different countries to find that out.\n",
    "* Calculate the fatality rate and how it changes over time. You may want to take into account the length of the disease in days to shift one time series before doing calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "You may look at further studies of COVID epidemic spread in the following publications:\n",
    "* [Sliding SIR Model for Rt Estimation during COVID Pandemic](https://soshnikov.com/science/sliding-sir-model-for-rt-estimation/), blog post by [Dmitry Soshnikov](http://soshnikov.com)\n",
    "* T.Petrova, D.Soshnikov, A.Grunin. [Estimation of Time-Dependent Reproduction Number for Global COVID-19 Outbreak](https://www.preprints.org/manuscript/202006.0289/v1). *Preprints* **2020**, 2020060289 (doi: 10.20944/preprints202006.0289.v1)\n",
    "* [Code for the above paper on GitHub](https://github.com/shwars/SlidingSIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "Thanks to Microsoft for creating the open-source course [Data Science for Beginners](https://github.com/microsoft/Data-Science-For-Beginners). It inspires the majority of the content in this chapter.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda_1",
   "language": "python",
   "name": "myconda_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
