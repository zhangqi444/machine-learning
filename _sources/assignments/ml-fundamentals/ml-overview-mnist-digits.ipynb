{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit Recognizer\n",
    "\n",
    "Although this is a computer vision problem, we employ here a simple model using **K-Nearest Neighbors** algorithm in this notebook to be a good starting point. We use the **GridSearchCV** to fine tune the hyperparameters such as *\"n_neighbors\", and \"weights\"*. Furthermore, we use **Data Augmentation** or **Artificial Data Synthesis** technique in this notebook to boost the model's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # Linear algebra\n",
    "import pandas as pd # For data manipulation\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt # For visualization\n",
    "from sklearn.neighbors import KNeighborsClassifier # For modelling\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV # For evaluation and hyperparameter tuning\n",
    "from sklearn.metrics import confusion_matrix, classification_report # For evaluation\n",
    "from scipy.ndimage import shift, rotate, zoom # For data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Peeking the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the datasets into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../../assets/data/mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"../../assets/data/mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing about the features in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Columns: 785 entries, label to 28x28\n",
      "dtypes: int64(785)\n",
      "memory usage: 35.9 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 785 entries, label to 28x28\n",
      "dtypes: int64(785)\n",
      "memory usage: 6.0 MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the train and test dataframes into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6000, 784)\n",
      "y_train shape: (6000,)\n",
      "X_test shape: (1000, 784)\n",
      "y_test shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.iloc[:6000, 1:].values\n",
    "y_train = train_df.iloc[:6000, 0].values\n",
    "X_test = test_df.iloc[:1000, 1:].values\n",
    "y_test = test_df.iloc[:1000, 0].values\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing a digit from the training data as a 28 X 28 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit = X_train[46]\n",
    "\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "print(f\"Label: {y_train[40]}\")\n",
    "plt.imshow(some_digit_image, cmap=\"binary\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.885     1.000     0.939       100\n",
      "           1      0.877     1.000     0.935       100\n",
      "           2      1.000     0.890     0.942       100\n",
      "           3      0.903     0.930     0.916       100\n",
      "           4      0.918     0.890     0.904       100\n",
      "           5      0.882     0.900     0.891       100\n",
      "           6      0.949     0.940     0.945       100\n",
      "           7      0.904     0.850     0.876       100\n",
      "           8      0.951     0.780     0.857       100\n",
      "           9      0.832     0.890     0.860       100\n",
      "\n",
      "    accuracy                          0.907      1000\n",
      "   macro avg      0.910     0.907     0.906      1000\n",
      "weighted avg      0.910     0.907     0.906      1000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator = KNeighborsClassifier()\n",
    "estimator.fit(X_train, y_train)\n",
    "predictions = estimator.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions, digits=3), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100   0   0   0   0   0   0   0   0   0]\n",
      " [  0 100   0   0   0   0   0   0   0   0]\n",
      " [  3   2  89   1   0   1   1   2   1   0]\n",
      " [  0   0   0  93   0   2   0   0   2   3]\n",
      " [  1   1   0   0  89   0   2   0   0   7]\n",
      " [  1   0   0   4   1  90   1   2   0   1]\n",
      " [  2   1   0   0   2   1  94   0   0   0]\n",
      " [  0   9   0   0   1   0   0  85   0   5]\n",
      " [  2   1   0   4   4   6   1   2  78   2]\n",
      " [  4   0   0   1   0   2   0   3   1  89]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning the model by finding the best values for the hyperparameters (weights, n_neighbors) using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9448333333333334\n",
      "\n",
      "Best Parameters: \n",
      "{\n",
      "    \"n_neighbors\": 3,\n",
      "    \"weights\": \"distance\"\n",
      "}\n",
      "\n",
      "Grid Search CV results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.607185</td>\n",
       "      <td>0.200978</td>\n",
       "      <td>11.994038</td>\n",
       "      <td>0.201209</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 3, 'weights': 'distance'}</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.939167</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.948333</td>\n",
       "      <td>0.944833</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.332688</td>\n",
       "      <td>0.063543</td>\n",
       "      <td>12.156543</td>\n",
       "      <td>0.449470</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td>0.948333</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.944167</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.940500</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.333111</td>\n",
       "      <td>0.074264</td>\n",
       "      <td>12.319519</td>\n",
       "      <td>0.475964</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'distance'}</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929167</td>\n",
       "      <td>0.938333</td>\n",
       "      <td>0.939167</td>\n",
       "      <td>0.936833</td>\n",
       "      <td>0.006737</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.269663</td>\n",
       "      <td>0.074638</td>\n",
       "      <td>12.240741</td>\n",
       "      <td>0.395837</td>\n",
       "      <td>9</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 9, 'weights': 'distance'}</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.936833</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.387173</td>\n",
       "      <td>0.116225</td>\n",
       "      <td>11.737193</td>\n",
       "      <td>0.944839</td>\n",
       "      <td>11</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 11, 'weights': 'distance'}</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.930833</td>\n",
       "      <td>0.930833</td>\n",
       "      <td>0.929167</td>\n",
       "      <td>0.933167</td>\n",
       "      <td>0.004453</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.607185      0.200978        11.994038        0.201209   \n",
       "1       1.332688      0.063543        12.156543        0.449470   \n",
       "2       1.333111      0.074264        12.319519        0.475964   \n",
       "3       1.269663      0.074638        12.240741        0.395837   \n",
       "4       1.387173      0.116225        11.737193        0.944839   \n",
       "\n",
       "  param_n_neighbors param_weights                                      params  \\\n",
       "0                 3      distance   {'n_neighbors': 3, 'weights': 'distance'}   \n",
       "1                 5      distance   {'n_neighbors': 5, 'weights': 'distance'}   \n",
       "2                 7      distance   {'n_neighbors': 7, 'weights': 'distance'}   \n",
       "3                 9      distance   {'n_neighbors': 9, 'weights': 'distance'}   \n",
       "4                11      distance  {'n_neighbors': 11, 'weights': 'distance'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.945833           0.945833           0.939167           0.945000   \n",
       "1           0.948333           0.935000           0.932500           0.944167   \n",
       "2           0.947500           0.930000           0.929167           0.938333   \n",
       "3           0.942500           0.937500           0.932500           0.936667   \n",
       "4           0.941667           0.933333           0.930833           0.930833   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.948333         0.944833        0.003046                1  \n",
       "1           0.942500         0.940500        0.005883                2  \n",
       "2           0.939167         0.936833        0.006737                3  \n",
       "3           0.935000         0.936833        0.003308                4  \n",
       "4           0.929167         0.933167        0.004453                5  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params = {\n",
    "    \"weights\": ['distance'],\n",
    "    \"n_neighbors\": [3,  5, 7, 9, 11]\n",
    "}\n",
    "\n",
    "estimator = KNeighborsClassifier()\n",
    "grid_estimator = GridSearchCV(estimator, # Base estimator\n",
    "                              grid_params, # Parameters to tune\n",
    "                              verbose=2, # Verbosity of the logs\n",
    "                              n_jobs=-1) # Number of jobs to be run concurrently with -1 meaning all the processors\n",
    "\n",
    "# Fitting the estimator with training data\n",
    "grid_estimator.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Score: {grid_estimator.best_score_}\", end=\"\\n\\n\")\n",
    "print(f\"Best Parameters: \\n{json.dumps(grid_estimator.best_params_, indent=4)}\",\n",
    "      end=\"\\n\\n\")\n",
    "print(\"Grid Search CV results:\")\n",
    "results_df = pd.DataFrame(grid_estimator.cv_results_)\n",
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best parameter values found:** {n_neighbors: 3, weights: 'distance'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a new model with the found hyperparameter values to the training data and making predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "estimator.fit(X_train, y_train)\n",
    "predictions = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0, 100,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  5,   1,  87,   2,   0,   0,   2,   2,   1,   0],\n",
       "       [  0,   0,   0,  93,   0,   2,   0,   0,   2,   3],\n",
       "       [  1,   1,   0,   0,  86,   0,   2,   0,   0,  10],\n",
       "       [  0,   0,   0,   5,   0,  91,   0,   2,   0,   2],\n",
       "       [  2,   1,   0,   0,   2,   1,  94,   0,   0,   0],\n",
       "       [  0,   9,   0,   0,   1,   0,   0,  85,   0,   5],\n",
       "       [  3,   0,   0,   4,   1,   3,   1,   2,  84,   2],\n",
       "       [  2,   0,   0,   0,   0,   1,   0,   3,   3,  91]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.885     1.000     0.939       100\n",
      "           1      0.893     1.000     0.943       100\n",
      "           2      1.000     0.870     0.930       100\n",
      "           3      0.894     0.930     0.912       100\n",
      "           4      0.956     0.860     0.905       100\n",
      "           5      0.929     0.910     0.919       100\n",
      "           6      0.949     0.940     0.945       100\n",
      "           7      0.904     0.850     0.876       100\n",
      "           8      0.933     0.840     0.884       100\n",
      "           9      0.805     0.910     0.854       100\n",
      "\n",
      "    accuracy                          0.911      1000\n",
      "   macro avg      0.915     0.911     0.911      1000\n",
      "weighted avg      0.915     0.911     0.911      1000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions, digits=3), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Augmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image in the training set is \n",
    "\n",
    "* shifted down, up, left and right by one pixel\n",
    "* rotated clockwise and anti-clockwise \n",
    "* clipped and zoomed at two different ranges\n",
    "\n",
    "generating eight different images. The image is clipped before zooming to preserve the image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_add shape: (48000, 784)\n",
      "y_train_add shape: (48000,)\n"
     ]
    }
   ],
   "source": [
    "def shift_in_one_direction(image, direction):\n",
    "    \"\"\"\n",
    "    Shifts an image by one pixel in the specified direction\n",
    "    \"\"\"\n",
    "    if direction == \"DOWN\":\n",
    "        image = shift(image, [1, 0])\n",
    "    elif direction == \"UP\":\n",
    "        image = shift(image, [-1, 0])\n",
    "    elif direction == \"LEFT\":\n",
    "        image = shift(image, [0, -1])\n",
    "    else:\n",
    "        image = shift(image, [0, 1])\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def shift_in_all_directions(image):\n",
    "    \"\"\"\n",
    "    Shifts an image in all the directions by one pixel\n",
    "    \"\"\"\n",
    "    reshaped_image = image.reshape(28, 28)\n",
    "\n",
    "    down_shifted_image = shift_in_one_direction(reshaped_image, \"DOWN\")\n",
    "    up_shifted_image = shift_in_one_direction(reshaped_image, \"UP\")\n",
    "    left_shifted_image = shift_in_one_direction(reshaped_image, \"LEFT\")\n",
    "    right_shifted_image = shift_in_one_direction(reshaped_image, \"RIGHT\")\n",
    "\n",
    "    return (down_shifted_image, up_shifted_image,\n",
    "            left_shifted_image, right_shifted_image)\n",
    "\n",
    "\n",
    "def rotate_in_all_directions(image, angle):\n",
    "    \"\"\"\n",
    "    Rotates an image clockwise and anti-clockwise\n",
    "    \"\"\"\n",
    "    reshaped_image = image.reshape(28, 28)\n",
    "    \n",
    "    rotated_images = (rotate(reshaped_image, angle, reshape=False),\n",
    "                      rotate(reshaped_image, -angle, reshape=False))\n",
    "    \n",
    "    return rotated_images\n",
    "\n",
    "\n",
    "def clipped_zoom(image, zoom_ranges):\n",
    "    \"\"\"\n",
    "    Clips and zooms an image at the specified zooming ranges\n",
    "    \"\"\"\n",
    "    reshaped_image = image.reshape(28, 28)\n",
    "    \n",
    "    h, w = reshaped_image.shape\n",
    "    \n",
    "    zoomed_images = []\n",
    "    for zoom_range in zoom_ranges:\n",
    "        zh = int(np.round(h / zoom_range))\n",
    "        zw = int(np.round(w / zoom_range))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "        \n",
    "        zoomed_images.append(zoom(reshaped_image[top:top+zh, left:left+zw],\n",
    "                                  zoom_range))\n",
    "    \n",
    "    return zoomed_images\n",
    "\n",
    "def alter_image(image):\n",
    "    \"\"\"\n",
    "    Alters an image by shifting, rotating, and zooming it\n",
    "    \"\"\"\n",
    "    shifted_images = shift_in_all_directions(image)\n",
    "    rotated_images = rotate_in_all_directions(image, 10)\n",
    "    zoomed_images = clipped_zoom(image, [1.1, 1.2])\n",
    "            \n",
    "    return np.r_[shifted_images, rotated_images, zoomed_images]\n",
    "\n",
    "X_train_add = np.apply_along_axis(alter_image, 1, X_train).reshape(-1, 784)\n",
    "y_train_add = np.repeat(y_train, 8)\n",
    "\n",
    "print(f\"X_train_add shape: {X_train_add.shape}\")\n",
    "print(f\"y_train_add shape: {y_train_add.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the synthesized data with the actual training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_combined shape: (54000, 784)\n",
      "y_train_combined shape: (54000,)\n"
     ]
    }
   ],
   "source": [
    "X_train_combined = np.r_[X_train, X_train_add]\n",
    "y_train_combined = np.r_[y_train, y_train_add]\n",
    "\n",
    "del X_train\n",
    "del X_train_add\n",
    "del y_train\n",
    "del y_train_add\n",
    "\n",
    "print(f\"X_train_combined shape: {X_train_combined.shape}\")\n",
    "print(f\"y_train_combined shape: {y_train_combined.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a new model with the tuned hyperparameters to the combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdata_estimator = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "cdata_estimator.fit(X_train_combined, y_train_combined)\n",
    "cdata_estimator_predictions = cdata_estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99,   0,   0,   0,   0,   1,   0,   0,   0,   0],\n",
       "       [  0, 100,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   3,  93,   0,   0,   0,   1,   3,   0,   0],\n",
       "       [  0,   0,   0,  93,   0,   3,   0,   2,   1,   1],\n",
       "       [  0,   1,   0,   0,  93,   0,   2,   0,   0,   4],\n",
       "       [  0,   0,   0,   4,   0,  93,   1,   2,   0,   0],\n",
       "       [  1,   1,   0,   0,   2,   1,  95,   0,   0,   0],\n",
       "       [  0,   7,   1,   0,   0,   0,   0,  91,   0,   1],\n",
       "       [  0,   0,   0,   2,   3,   5,   1,   2,  85,   2],\n",
       "       [  1,   0,   0,   0,   0,   2,   0,   2,   1,  94]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, cdata_estimator_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.980     0.990     0.985       100\n",
      "           1      0.893     1.000     0.943       100\n",
      "           2      0.989     0.930     0.959       100\n",
      "           3      0.939     0.930     0.935       100\n",
      "           4      0.949     0.930     0.939       100\n",
      "           5      0.886     0.930     0.907       100\n",
      "           6      0.950     0.950     0.950       100\n",
      "           7      0.892     0.910     0.901       100\n",
      "           8      0.977     0.850     0.909       100\n",
      "           9      0.922     0.940     0.931       100\n",
      "\n",
      "    accuracy                          0.936      1000\n",
      "   macro avg      0.938     0.936     0.936      1000\n",
      "weighted avg      0.938     0.936     0.936      1000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, cdata_estimator_predictions, digits=3), end=\"\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** With **Data Augmentation** the accuracy jumped from 91.6% to 95.3% on the test data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "Thanks to SkalskiP for creating the open-source [Kaggle jupyter notebook](https://www.kaggle.com/code/gauthampughazh/digit-recognition-using-knn), licensed under Apache 2.0. It inspires the majority of the content of this assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
